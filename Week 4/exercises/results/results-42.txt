4.2.1
For all of the tests it's clear that the function's runtime becomes a lot faster the more times it is run. This is probably due to java's 'Just In Time' optimizations that are put into action when Java's sees enough recurrent patterns so it can improve the run time by caching and other things.
Also the standard deviation goes down as the number of runs goes up, which is expected as more samples leads to higher precision.
It's also possible to see irregularities in the pattern of decreasing runtimes and standard deviations. 
For example when looking at our results for Point Creation the runtime and std. deviation both jumps at a specific run, compared to its predecessors. This could be due to some background process running at the same time that interferes with the result.


4.2.2
# OS:   Mac OS X; 10.11.3; x86_64
# JVM:  Oracle Corporation; 1.8.0_60
# CPU:  null; 4 "cores"
# Date: 2016-09-23T11:22:08+0200
hashCode()                            3,7 ns       0,07   67108864
Point creation                      102,0 ns       0,97    4194304
Thread's work                      8752,2 ns     108,95      32768
Thread create                      1330,0 ns      18,49     262144
Thread create start               69513,6 ns    3986,01       4096
Thread create start join          86746,3 ns    3211,42       4096
ai value = 819140000
Uncontended lock                      8,3 ns       0,09   33554432

Are they plausible? Any surprises?
Mention any cases where they deviate significantly from those shown in the lecture

All of the results are very similar to the ones from the lecture for Intel i7. 
The results are all a bit slower, which makes sense since my processor is Intel i5. 
The only major deviation is the std. deviation for thread create start where the result from the lecture is 320 and mine is 2600. 



